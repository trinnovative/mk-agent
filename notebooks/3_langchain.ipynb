{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:17.714499700Z",
     "start_time": "2023-11-29T16:43:17.438433200Z"
    }
   },
   "id": "af6a1b4b9056f760"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain\n",
    "- Open-source Framework\n",
    "- Python, JS/TS\n",
    "- Kombination von LLMs mit externen Funktionalitäten und Daten"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387bdd6d05b1275a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model I/O\n",
    "\n",
    "### Prompts\n",
    "Die Anweisung/Frage/Aufgabestellung die das Modell bearbeiten soll.\n",
    "\n",
    "### Language Models\n",
    "Interfaces und Integrationen von verschiedenen Modellen\n",
    "- LLMs: input text → output text (z.B. `text-davinci-003`)\n",
    "- Chat models: input Liste von Chatnachrichten (System, Human, AI) → output Chatnachricht (z.B. `gpt-3.5-turbo`)\n",
    "\n",
    "### Output Parsers\n",
    "Wandeln die Textausgabe der Modelle in strukturierte Daten um."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82bd7bdd6e6b99"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant who generates comma separated lists. A user will pass in a category, and you should generate 5 objects in that category in a comma separated list. ONLY return a comma separated list, and nothing more.'), HumanMessage(content='programming languages')])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = (\"You are a helpful assistant who generates comma separated lists. \"\n",
    "                   \"A user will pass in a category, and you should generate 5 objects in that category in a comma separated list. \"\n",
    "                   \"ONLY return a comma separated list, and nothing more.\")\n",
    "human_template = \"{text}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "prompt_template.invoke({\"text\": \"programming languages\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:17.717502200Z",
     "start_time": "2023-11-29T16:43:17.471687800Z"
    }
   },
   "id": "476618f2b18ea11b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='Hello! How can I assist you today?')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# default: gpt-3.5-turbo\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm.invoke(\"hi!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:19.054148400Z",
     "start_time": "2023-11-29T16:43:17.501500900Z"
    }
   },
   "id": "a8f9650d71065b79"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "['python', 'typescript']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "parser.invoke(\"python, typescript\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:19.056155200Z",
     "start_time": "2023-11-29T16:43:19.054148400Z"
    }
   },
   "id": "6e83e45ece34069b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chains\n",
    "Chains erlauben es mehrere Modelle (LLM, Chat) und Komponenten (Prompt, Parser, Retriever) zu verknüpfen.\n",
    "Für das Erstellen von Chains wird vorrangig die [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/) verwendet.\n",
    "\n",
    "```python\n",
    "chain = prompt | model | parser\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5c0d2fa441f23e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['Python', 'Java', 'C++', 'JavaScript', 'Ruby']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm | parser\n",
    "\n",
    "chain.invoke({\"text\": \"programming languages\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:19.730602700Z",
     "start_time": "2023-11-29T16:43:19.059175Z"
    }
   },
   "id": "5f727cd73d7a8e80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Memory\n",
    "- Informationen aus vorausgegangenen Konversationen speichern\n",
    "- Speichern und abrufen von Informationen (reading/writing)\n",
    "- Mit Tokenlimit umgehen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e250ac5d8db585f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:19.740093500Z",
     "start_time": "2023-11-29T16:43:19.728567600Z"
    }
   },
   "id": "411c67a682be4716"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hi! My name is Dave\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'hi! My name is Dave',\n 'history': '',\n 'response': \"Hello Dave! It's nice to meet you. How can I assist you today?\"}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"hi! My name is Dave\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:21.058798Z",
     "start_time": "2023-11-29T16:43:19.740093500Z"
    }
   },
   "id": "991584c565d5f45b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi! My name is Dave\n",
      "AI: Hello Dave! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'What is my name?',\n 'history': \"Human: hi! My name is Dave\\nAI: Hello Dave! It's nice to meet you. How can I assist you today?\",\n 'response': 'Your name is Dave.'}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"What is my name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:22.086683700Z",
     "start_time": "2023-11-29T16:43:21.061779900Z"
    }
   },
   "id": "e53594d26eb47c07"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='hi! My name is Dave'),\n AIMessage(content=\"Hello Dave! It's nice to meet you. How can I assist you today?\"),\n HumanMessage(content='What is my name?'),\n AIMessage(content='Your name is Dave.')]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.memory.chat_memory.messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:22.096982500Z",
     "start_time": "2023-11-29T16:43:22.086683700Z"
    }
   },
   "id": "717ee77c618fd524"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieval\n",
    "- Einbindung von Daten, die nicht Teil des Trainingssets des Modells sind\n",
    "- Retrieval Augmented Generation (RAG) \n",
    "- Dokumente laden/transformieren, Embeddings, Vector Stores, Retrievers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5396deb3f3274e68"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:22.109849900Z",
     "start_time": "2023-11-29T16:43:22.094983100Z"
    }
   },
   "id": "910c614705506fc7"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts([\"Hacky Hour: Large Language Models for Developers \"\n",
    "                                \"anwenden, integrieren und erweitern, \"\n",
    "                                \"Degginger Regensburg, 14.11.2023, Einlass 18:00 Uhr, Start 18:30 Uhr\"], embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:22.404102100Z",
     "start_time": "2023-11-29T16:43:22.105852200Z"
    }
   },
   "id": "bb51de2626858328"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'Die Hacky Hour findet am 14.11.2023 in Degginger Regensburg statt.'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Wann und wo findet die Hacky Hour statt?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:24.296755200Z",
     "start_time": "2023-11-29T16:43:22.406100Z"
    }
   },
   "id": "7f1f57bc55d4996c"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'Die Hacky Hour startet um 18:30 Uhr.'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Um wie viel Uhr Startet die Hacky Hour?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:26.014019600Z",
     "start_time": "2023-11-29T16:43:24.298758800Z"
    }
   },
   "id": "188c38a026e3aedf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agents\n",
    "- Agents erlauben LLMs mit ihrer Umgebung zu interagieren (Funktionen, APIs).\n",
    "- LLMs werden als Reasoning-Engine genutzt um zu entscheiden welche Aktionen ausgeführt werden sollen (Chains sind hardcoded)\n",
    "- AgentAction: Welche Aktion soll ausgeführt werden (tool, tool_input)\n",
    "- AgentFinish: Ist der Agent mit seiner Arbeit fertig und soll das Ergebnis zurückgeben\n",
    "- intermediate_steps: Welche Schritte wurden bereits ausgeführt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac938ff65cd88e25"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:26.022575400Z",
     "start_time": "2023-11-29T16:43:26.018058300Z"
    }
   },
   "id": "f77b98fb97c36bcb"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-0613\", temperature=0)\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=llm)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:26.070431700Z",
     "start_time": "2023-11-29T16:43:26.022575400Z"
    }
   },
   "id": "2e9b0da2a78d57a8"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": \"Leonardo DiCaprio's current girlfriend\"\n",
      "}\n",
      "```\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mLeonardo DiCaprio spent Thanksgiving with his girlfriend Vittoria Ceretti's family. The \"Titanic\" actor, 49, was spotted stepping out with the 25-year-old model's kin in London on Thursday,... Leonardo DiCaprio was accompanied by new girlfriend Vittoria Ceretti as he celebrated his 49th birthday with a star-studded soirée in Beverly Hills, Calif., Saturday night. The \"Titanic\" star... Eileen Reslen Published Sep. 22, 2023, 5:15 p.m. ET Leonardo DiCaprio is officially dating Vittoria Ceretti, Page Six can confirm. Getty Images for Global Citizen More On: leonardo... Leonardo DiCaprio's new girlfriend, Vittoria Ceretti, and his ex-fling Gigi Hadid had a fashion face-off on the catwalk on Friday, both taking turns strutting their stuff in the Versace... Jeff J Mitchell/Getty Images Welcome to a new NPR series where we spotlight the people and things making headlines — and the stories behind them. The 48-year-old generated outrage online when it...\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"Calculator\",\n",
      "    \"action_input\": \"25 * 3\"\n",
      "}\n",
      "```\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 75\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\"\n",
      "}\n",
      "```\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?',\n 'chat_history': [HumanMessage(content='Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?'),\n  AIMessage(content=\"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\")],\n 'output': \"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\"}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:43:43.015041100Z",
     "start_time": "2023-11-29T16:43:26.046853300Z"
    }
   },
   "id": "b08a8f0b88e972f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI function with LangChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0746556627ee522"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, date, unit=\"celsius\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"-4\",\n",
    "        \"unit\": unit,\n",
    "        \"date\": date,\n",
    "        \"forecast\": [\"snow\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:57:17.118504100Z",
     "start_time": "2023-11-29T16:57:17.084489500Z"
    }
   },
   "id": "3b7fac4b8bd27193"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from enum import Enum\n",
    "from datetime import date\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-0613\", temperature=0)\n",
    "\n",
    "class TemperatureScale(str, Enum):\n",
    "    CELSIUS = \"celsius\"\n",
    "    FAHRENHEIT = \"fahrenheit\"\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    location: str = Field(description=\"The city\")\n",
    "    date: str = Field( description=\"The date\")\n",
    "    unit: TemperatureScale = Field(default=TemperatureScale.CELSIUS)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    StructuredTool(\n",
    "        name=\"get_current_weather\",\n",
    "        func=get_current_weather,\n",
    "        description=\"Get the current weather in a given city at a given date\",\n",
    "        args_schema=WeatherInput\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    max_execution_time=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:57:17.668362100Z",
     "start_time": "2023-11-29T16:57:17.657840900Z"
    }
   },
   "id": "123013e1d2313ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `get_current_weather` with `{'location': 'Munich', 'date': '2023-12-02'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{\"location\": \"Munich\", \"temperature\": \"-4\", \"unit\": \"celsius\", \"date\": \"2023-12-02\", \"forecast\": [\"snow\", \"windy\"]}\u001B[0m\u001B[32;1m\u001B[1;3mGiven the weather forecast for Munich on 2nd December 2023, it's going to be quite cold with a temperature of -4 degrees Celsius and there will be snow and wind. \n",
      "\n",
      "Here are some indoor activities you might enjoy:\n",
      "\n",
      "1. **Visit the Museums**: Munich is home to many world-class museums. You could visit the Deutsches Museum, which is the world's largest museum of science and technology, or the Munich Residenz, which is the former royal palace of the Wittelsbach monarchs of Bavaria.\n",
      "\n",
      "2. **Enjoy the Christmas Markets**: Despite the cold, the Christmas markets in Munich are a must-visit. You can enjoy a warm mug of Glühwein (mulled wine), buy some Christmas decorations or gifts, and enjoy the festive atmosphere.\n",
      "\n",
      "3. **Explore the Munich's Breweries**: Munich is famous for its beer and breweries. You can take a tour of some of the city's most famous breweries and enjoy a warm meal.\n",
      "\n",
      "4. **Visit the Bavarian National Opera**: If you're a fan of music, you might enjoy a performance at the Bavarian National Opera.\n",
      "\n",
      "Remember to dress warmly and stay safe!\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': \"What's your suggestion for holiday activity in Munich at 2nd December 2023?\",\n 'output': \"Given the weather forecast for Munich on 2nd December 2023, it's going to be quite cold with a temperature of -4 degrees Celsius and there will be snow and wind. \\n\\nHere are some indoor activities you might enjoy:\\n\\n1. **Visit the Museums**: Munich is home to many world-class museums. You could visit the Deutsches Museum, which is the world's largest museum of science and technology, or the Munich Residenz, which is the former royal palace of the Wittelsbach monarchs of Bavaria.\\n\\n2. **Enjoy the Christmas Markets**: Despite the cold, the Christmas markets in Munich are a must-visit. You can enjoy a warm mug of Glühwein (mulled wine), buy some Christmas decorations or gifts, and enjoy the festive atmosphere.\\n\\n3. **Explore the Munich's Breweries**: Munich is famous for its beer and breweries. You can take a tour of some of the city's most famous breweries and enjoy a warm meal.\\n\\n4. **Visit the Bavarian National Opera**: If you're a fan of music, you might enjoy a performance at the Bavarian National Opera.\\n\\nRemember to dress warmly and stay safe!\"}"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\"What's your suggestion for holiday activity in Munich at 2nd December 2023?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T16:57:49.359546300Z",
     "start_time": "2023-11-29T16:57:18.672096600Z"
    }
   },
   "id": "2d4ba39327567774"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b43283ad5551039a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
